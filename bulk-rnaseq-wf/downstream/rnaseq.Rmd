
```{r, include=FALSE}
# =============================================================================
# IMPORTANT:
# Before running this, search for the string "NOTE:". This indicates parts of
# the file that need to be changed depending on the experiment.
# =============================================================================
#
# This Rmd file aims to include "the works", with some preliminary exploratory
# visualizations, followed by differential expression using both gene models
# and transcript models (with examples of interaction) SVA, and some downstream
# GO analysis.
#
# Look for the string "NOTE:" to identify places that may need some editing.
# Notably, the only model run by default is `~group`, which will only be
# appropriate for the simplest experiments.

# There are a fair amount of helper functions. They are stored in
# `helpers.Rmd`, and included here as a child document so that all code is
# self-contained in the HTML rendered from this RMarkdown.
#-----------------------------------------------------------------------------
```

```{r, include=FALSE}
knitr::opts_chunk$set(collapse=TRUE, warning=FALSE, message=FALSE,
                      bootstrap.show.code=FALSE, bootstrap.show.output=FALSE,

                      # try disabling this when running locally for nicer figures
                      #dev='bitmap',

                      fig.ext='png')
```
# RNA-seq results

```{r, include=FALSE}
# NOTE: Here's a template for including a link that will load a prepared track
# hub. It is not included by default.

# [Load hub and prepared session on UCSC Genome
# Browser](http://genome.ucsc.edu/cgi-bin/hgTracks?db=ASSEMBLY&hubUrl=https://HOST/PATH/hub.txt&hgS_loadUrlName=https://HOST/PATH/session.txt&hgS_doLoadUrl=submit&position=chr1:1-100)
```

```{r imports}
library(DESeq2)
library(gridExtra)
library(ggplot2)
library(genefilter)
library(readr)
library(tximport)
library(clusterProfiler)
library(AnnotationHub)
library(BiocParallel)
library(UpSetR)
```

```{r child='helpers.Rmd'}
# When running interactively, run the following to load helper functions.
# When rendering this file, the contents of this code block will be skipped
# since it is a "child" block for which all contents are expected to be in
# the other file.
rmarkdown::render('helpers.Rmd', run_pandoc=FALSE)
```

```{r annotationhub_setup}
# NOTE: try disabling this when running locally to get nicer figures:
# options(bitmapType='cairo')

# NOTE: Change these to reflect organism you're working with.
#   e.g., 'Mus musculus', 'mmu'; 'Homo sapiens', 'hsa'. You can also provide an
#   annotation key to override if you know the one to use, otherwise leave NA.
annotation_genus_species <- 'Drosophila melanogaster'
kegg.org <- 'dme'
annotation_key_override <- NA

hub.cache <- '../../../include/AnnotationHubCache'

# To ensure that we do not clobber any local copies of the annotation, we copy
# to tmp. This also should increase performance when running on the cluster --
# we avoid poor sqlite performance on shared filesystems by copying to
# local scratch space.
file.copy(hub.cache, tempdir(), recursive=TRUE)
new.cache <- file.path(tempdir(), 'AnnotationHubCache')

orgdb <- get.orgdb(
    annotation_genus_species,
    cache=new.cache,
    annotation_key_override=annotation_key_override
)
```

```{r coldata_setup}
# NOTE: path name to sampletable
sample.table.filename = '../config/sampletable.tsv'

colData <- read.table(sample.table.filename, sep='\t', header=TRUE)

# NOTE: Specify which featureCounts strandedness to use.
#
#   All three are created by default in the workflow, but here is where you
#   specify which one to use for differential expression.

featurecounts.strandedness <- 's0'  # unstranded
# featurecounts.strandedness <- 's1' # plus-strand reads correspond to sense-strand transcription (e.g., Ovation kits)
# featurecounts.strandedness <- 's2' # minus-strand reads correspond to sense-strand transcription (e.g., TruSeq kits)

# NOTE: Paths to featureCounts output.
#
#   This is configured in the patterns and targets from the workflow; if you've
#   changed anything there you will need to change it here as well.
colData$featurecounts.path <- sapply(
    colData$samplename,
    function (x) file.path(
        '..', 'data', 'rnaseq_samples', x,
        paste0(x, '.cutadapt.bam.featurecounts.', featurecounts.strandedness, '.txt')
        )
    )

# NOTE: Paths to Salmon output.
#
#    This is configured in the patterns and targets from the workflow; if
#    you've changed anything there you will need to change it here as well.
colData$salmon.path <- sapply(
    colData$samplename,
    function (x) file.path('..', 'data', 'rnaseq_samples', x, paste0(x, '.salmon'), 'quant.sf')
)

# NOTE: Factor columns.
#
#    These are the columns in the sampletable that should be converted to
#    factors
factor.columns <- c('group')

# NOTE: Which columns to exclude from printing.
#
#   If you have very verbose metadata in your sampletable you can exclude those
#   columns here.
exclude.for.printing <- c('featurecounts.path', 'salmon.path', 'orig_filename')
for (col in factor.columns){
    colData[[col]] <- as.factor(colData[[col]])
}

# NOTE: Relevel the factors.
#
#   For the test data, "control" is the base level for the "group" factor, but
#   you will need to edit as appropriate for your experimenal design.
colData$group <- relevel(colData$group, ref='control')
```
## Experiment overview

Here is the sample table with metadata used for this analysis:

```{r}
knitr::kable(colData[, colnames(colData)[!colnames(colData) %in% exclude.for.printing]])
```

```{r salmon}
# Load transcript-level counts
txi <- tximport(colData[, 'salmon.path'], type='salmon', txOut=TRUE)
transcript.tpm <- txi$abundance
colnames(transcript.tpm) <- colData$samplename
```

```{r ddstxi, cache=TRUE, eval=TRUE}
dds.txi <- DESeqDataSetFromTximport(
    txi, colData=colData[, -grepl('path', colnames(colData)), drop=FALSE],

    # NOTE: design to use when importing Salmon data.
    design=~group
)

# Normalize transcript counts for heatmaps and PCA. We're using vst rather than
# rlog because the DESeq2 docs say they are largely equivalent, and vst is
# substantially faster.
#
# Since this is for exploratory data analysis, we use blind=TRUE
# to ignore the design.
rld.txi <- varianceStabilizingTransformation(dds.txi, blind=TRUE)
```


```{r dds_initial, cache=TRUE}
# Load gene-level counts
dds <- DESeqDataSetFromFeatureCounts(
    sampleTable=colData,
    directory='.',
    # NOTE: What design to use?
    #
    #   This object will be used for EDA, so it's recommended to use a single
    #   factor that describes the samples
    design=~group)

# NOTE: Gene IDs with "." in them
#    If gene names came in as Ensembl "gene.version" IDs, here we split them to
#    only give the gene ID. If you want to keep existing "." in gene names,
#    comment out this line.
rownames(dds) <- sapply(strsplit(rownames(dds), '.', fixed=TRUE), function (x) x[1])

# Variance-stablilized transform to normalize gene-level counts.
# Alternatively, use `rlog`, but that gives about the same results
# and is slow for large numbers of samples.
#
# Since this is for exploratory data analysis, we use blind=TRUE
# to ignore the design.
rld <- varianceStabilizingTransformation(dds, blind=TRUE)
```

## Sample clustering and QC

The following heatmap shows a hierarchical clustering of pairwise distances
between samples. Darker blue means less distant (i.e. more similar). In general
we expect to see replicates clustering together and separation of treatments.

## Clustered heatmap

```{r}
# NOTE: Which columns to use for grouping the heatmap?
#
#    Add as many columns as you want for the last argument. The test data uses
#    just the "group" column to create colored boxes corresponding to values of
#    "group" alongside the heatmap.
#
plot.heatmap(rld, colData, c('group'))
```

## PCA

Another way of looking at sample clustering is principal components analysis
(PCA). The x- and y-axes do not have units, rather, they represent the
dimensions along which the samples vary the most. The amount of variance
explained by each principal component is indicated in the axes label.


```{r}
# NOTE: Which columns to use for grouping the heatmap?
#
#    See similiar note above for which columns to group by
plotPCA(rld, intgroup=c('group'))
```


## Most-varying genes

We can also look at the most varying genes to get a sense of the clustering.
This heatmap takes the top 50 most-varying genes and plots their deviation from
the row mean.

```{r, fig.height=12}
# NOTE: Which columns to use for grouping the heatmap?
#
#   See similiar note above for which columns to group by
vargenes.heatmap(rld, c('group'))
```

## Size factors
Size factors: ideally, all libraries were sequenced to identical depth, in
which case all size factors would be 1.0. In practice, this is almost never the
case. These size factor estimates are DESeq2's way of showing how sequencing
depth varies across libraries. If some libraries are much higher or lower than
1 then those libraries had dramatically different coverage and we should be
careful about interpreting results.

```{r}
dds <- estimateSizeFactors(dds)
sf <- sizeFactors(dds)
sf <- sf[order(sf)]
knitr::kable(sf)
```

```{r}
# NOTE: Run DESeq2 on multiple cores.
#
#    By default, we do not run in parallel, however this can be very useful in
#    experiments with many samples and complex designs.  To run in parallel,
#    comment out the line below and set cores appropriately. Then, add the
#    argument `parallel=TRUE` whenever you call DESeq()
#    register(MulticoreParam(4))
parallel <- FALSE
```

```{r dds_models, cache=TRUE}
# NOTE: gene rather than transcript counts
#
#    By default we use gene counts rather than transcript counts. See code
#    above where the `dds.txi` object is created for how to modify this for
#    transcript counts.
dds <- DESeqDataSetFromFeatureCounts(
    sampleTable=colData,
    directory='.',
    # NOTE: model to use
    #   This will be used for contrasts below.
    design=~group
)

# NOTE: If gene names came in as Ensembl "gene.version" IDs, here we split them
# to only give the gene ID.
rownames(dds) <- sapply(strsplit(rownames(dds), '.', fixed=TRUE), function (x) x[1])
dds <- DESeq(dds,
    # NOTE: betaPrior
    #
    #    betaPrior=FALSE is the default in DESeq2 >1.16, but here we set it
    #    explicitly for consistency across different versions.
    betaPrior=FALSE,
    parallel=parallel
    )
```


```{r results, cache=TRUE}
# NOTE: lots of editing likely needed in this chunk!
#
#    This is the block that performs the contrasts, filling out the `res.list`
#    named list, which ties together the results, the DESeq object from which the
#    results were extracted, and a descriptive label to be used in plots and
#    headings.
#
#    For each entry in `res.list`, you will get DE results sections automatically
#    created for each item. Each of these sections will have the "label" as its
#    header, and will contain a summary table, MA plots, counts plots of top 3 up-
#    and down-regulated genes, p-value distribution, and exported results tables
#    with links in the rendered HTML to the output files.
#
#    NOTE: Here are some notes on using lfcShrink...
#    As currently implemented (05 apr 2018), lfcShrink checks its arguments for an
#    existing results table. If it exists, it applies shrinkage to the lfc and se
#    in that table. If it *doesn't* exist, it calls results on dds with the syntax
#
#        res <- results(dds, name=coef)
#    or
#
#        res <- results(dds, contrast=contrast)
#
#    It does not pass any further arguments to results, and it doesn't warn you
#    that results-style arguments were unrecognized and ignored. Therefore,
#    lfcShrink DOES NOT directly support lfcThreshold, or other alternative
#    hypotheses, or any of the custom analysis methods you can access through
#    results(). To get those, you have to call results first, without shrinkage,
#    and then apply lfcShrink.
#
#    Here we use the lfcShrink version of the results. In DESeq2 versions >1.16,
#    the lfc shrinkage is performed in a separate step, so that's what we do here.
#    This is slightly different results than if you used betaPrior=TRUE when
#    creating the DESeq object.


# res.list is a named list. Each item should be a list with names c('res',
# 'dds', 'label'). "res" is a DESeqResults object, "dds" is the corresponding
# DESeq object the results were extracted from, and "label" is a nicer label to
# use for headers and other text.
res.list <- list()

# NOTE: Example contrast #1
#
#   Using the example data, this compares treatment group to control group.
#   Change to reflect your experiment.
res.list[['all']] <- list(
    res=lfcShrink(dds, contrast=c('group', 'treatment', 'control')),
    dds=dds,
    label='Using a log2FoldChange threshold of 0'
)


# NOTE: Example contrast #2
#
#    Using the example data, this compares treatment group to control group but
#    requiring genes to have >4-fold differences (log2(4) = 2). Change to
#    reflect your experiment.
res.lfcthresh.2 <- results(
    dds,
    contrast=c('group', 'treatment', 'control'),
    lfcThreshold=2)

res.list[['lfc2']] <- list(
    res=lfcShrink(
        dds,
        contrast=c('group', 'treatment', 'control'),
        res=res.lfcthresh.2
    ),
    dds=dds,
    label='Using a log2FoldChange threshold of >2'
)
```


```{r attach, cache=TRUE, depends='results'}
# NOTE: Assumes Ensembl Ids
keytype <- 'ENSEMBL'

# NOTE: Assumes that Symbol, Uniprot and alias columns are available in the
# OrgDb
columns <- c('SYMBOL', 'UNIPROT', 'ALIAS')

for (name in names(res.list)){
    res.list[[name]][['res']] <- attach.info(
        res.list[[name]][['res']],
        keytype=keytype,
        columns=columns)
}

# NOTE: Assumes using ENSEMBLTRANS transcript IDs with Salmon
#
#   If you're using something else, you may just want to skip this step.
transcript.geneids <- mapIds(orgdb,
                             keys=rownames(transcript.tpm),
                             column=keytype,
                             keytype='ENSEMBLTRANS')
```

# Differential expression

Here is a table summarizing the comparisons. See the [Background and
help](#Help) section for details.

```{r, results='asis'}
# Summarize all experiments
knitr::kable(summarize.res.list(res.list, dds.list, res.list.lookup))
```

For each comparison, we report:

- the line from the summary table for this comparison
- counts plots for the top 3 up- and top 3 down-regulated genes
- an M-A plot
- a p-value histogram

See the [Background and help](#Help) section for details on these.

```{r, results='asis'}
# NOTE: Which columns to add to the top plots' titles?
#
#    This will add nicer titles to the plots. These may have come from the
#    `attach.info` call above.
add_cols <- c('symbol', 'alias')

for (name in names(res.list)){
  dds.i <- res.list[[name]][['dds']]
  res.i <- res.list[[name]][['res']]
  label <- res.list[[name]][['label']]
  mdcat('## ', label)
  mdcat('### Summary of results')
  print(knitr::kable(my.summary(res.i, dds.i)))
  mdcat('### Normalized counts of top 3 upregulated genes')
  top.plots(padj.order(res.i), 3, my.counts, dds.i, add_cols)
  mdcat('### Normalized counts of top 3 downregulated genes')
  top.plots(padj.order(res.i, reverse=TRUE), 3, my.counts, dds.i, add_cols)
  mdcat('### M-A plot')
  plotMA(res.i)
  mdcat('### P-value distribution')
  pval.hist(res.i)
}
```


```{r, fig.width=12, results='asis'}
# UpSet plots only make sense for more than one set of genes. The Markdown
# explanatory text and the plots themselves are only created if res.list has
# multiple items in it.
if (length(res.list) > 1){
    mdcat("## UpSet plots")
    mdcat("Gather together all the interesting gene sets into an ",
          "['UpSet' plot](http://caleydo.org/tools/upset/). These plots show ",
          "the combinatorial overlaps of genes found to be up, down, and any ",
          "changed across the different contrasts performed.")

    ll <- lapply(res.list, get.sig, 'up')
    ll <- ll[lapply(ll, length) > 0]
    if (length(ll) > 1) {
        mdcat("### Upregulated UpSet plot:")
        upset(fromList(ll), order.by='freq', nsets=length(ll))
    }

    ll <- lapply(res.list, get.sig, 'down')
    ll <- ll[lapply(ll, length) > 0]
    if (length(ll) > 1) {
        mdcat("### Downregulated UpSet plot:")
        upset(fromList(ll), order.by='freq', nsets=length(ll))
    }

    ll <- lapply(res.list, get.sig, 'changed')
    ll <- ll[lapply(ll, length) > 0]
    if (length(ll) > 1) {
        mdcat("### Changed genes UpSet plot:")
        upset(fromList(ll), order.by='freq', nsets=length(ll))
    }
}
```

# Gene patterns

We can roughly group genes into expression patterns. This uses the [DEGreport
package](https://www.bioconductor.org/packages/release/bioc/html/DEGreport.html),
which in turn uses the
[ConsensusClusterPlus](https://www.bioconductor.org/packages/release/bioc/html/ConsensusClusterPlus.html)
algorithm to cluster genes into similar expression patterns. The lists of genes
found in each cluster are reported below the plot.

```{r, fig.width=12, results='asis', cache=TRUE}
# NOTE: which genes to plot?
#    By default, we get all the changed genes, but you may want only the up or
#    down genes.
ll <- lapply(res.list, function (x) get.sig(x[['res']], 'changed'))

# Filter out results where there were zero genes detected.
ll <- ll[lapply(ll, length) > 0]

for (name in names(ll)){
    genes <- ll[[name]]

    # NOTE: hard limit to number of genes
    #
    #    Plotting more genes than this will take a lot of time to perform the
    #    clustering.
    #
    #    If there are more than this limit, then we take a random sample.
    lim <- 2000
    if (length(genes) > lim){
        genes <- sample(genes, lim)
    }

    # Extract the normalized counts for these genes
    idx <- rownames(rld) %in% genes
    ma <- assay(rld)[idx,]

    # Print a nice Markdown header
    mdcat('## ', res.list[[name]][['label']])
    colData.i <- colData(res.list[[name]][['dds']])

    d <- degPatterns(
        ma,
        colData.i,

        # NOTE: "time" becomes the x-axis of the plot; change as appropriate to
        # your experiment
        time='group',

        # NOTE: reduce will merge clusters that are similar; similarity
        # determined by cutoff
        reduce=TRUE, cutoff=0.5,

        # NOTE: For more complicated designs, try the `col` argument to color
        # the plot by another factor.
        # col="another.column",

        # NOTE: increase min cluster size to 15
        # This is purposely set low for test data; the DEGreport default is 15.
        minc=1
        )

    # In the final_clusters directory, this creates files containing lists of
    # the genes in each cluster, and adds a link to the Markdown.
    dir.create('final_clusters')
    for (u in unique(d$df$cluster)){
        fn <- file.path('final_clusters',
                        paste0('final.', name, '.cluster.', u, '.txt'))
        write.table(d$df[d$df$cluster==u, 'genes'], file=fn, quote=FALSE,
                    row.names=FALSE, col.names=FALSE)
        mdcat('- [', fn, '](', fn, '), cluster "', u, '" genes')
    }
}
```

```{r groupcounts, cache=TRUE}
# NOTE: optionally disable this chunk
#
#    This chunk inspects the model matrix of the design, aggregates counts for
#    each of the levels in the design, and attaches them to each set of
#    results.
#
#    It also attaches normalized gene counts and Salmon TPM.
#
counts.list <- list()

# Compute aggregate (by gene) normalized transcript counts from Salmon
gene.tpm <- aggregate(transcript.tpm, list(transcript.geneids), sum)

# Use normalized counts to get per-level mean counts. Attach Salmon aggregate
# counts to each output file. This does *not* assume any particular model.
for (name in names(res.list)) {

    my.res <- res.list[[name]][['res']]
    my.dds <- res.list[[name]][['dds']]

    counts.list[[name]] <- my.res[,c("gene", "baseMean", "log2FoldChange", "lfcSE", "padj")]

    # get the DESeq2 normalized per-gene count data
    my.normalized.counts <- counts(my.dds, TRUE)
    colnames(gene.tpm) <- c("Gene", colnames(my.normalized.counts))

    # report per-sample Salmon counts to output files
    merged.results.deseq.counts <- merge(data.frame(my.res), my.normalized.counts, by.x="gene", by.y="row.names", all.x=TRUE, sort=FALSE)
    merged.results.salmon.tpm <- merge(data.frame(my.res), gene.tpm, by.x="gene", by.y="Gene", all.x=TRUE, sort=FALSE)
    rownames(merged.results.deseq.counts) <- merged.results.deseq.counts$gene
    rownames(merged.results.salmon.tpm)   <- merged.results.salmon.tpm$gene
    merged.results.deseq.counts           <- merged.results.deseq.counts[rownames(my.res),]
    merged.results.salmon.tpm <- merged.results.salmon.tpm[rownames(my.res),]
    rownames(merged.results.deseq.counts) <- NULL
    rownames(merged.results.salmon.tpm) <- NULL
    for (colname in colnames(my.normalized.counts)) {
        my.res[,paste('deseq2.counts', colname, sep='.')] <- merged.results.deseq.counts[,colname]
        my.res[,paste('avg.salmon.tpm', colname, sep='.')] <- merged.results.salmon.tpm[,colname]
    }

    # extract the design matrix
    my.model <- model.matrix(design(my.dds), colData(my.dds))

    # unique rows correspond to groups
    my.unique.patterns <- unique(my.model)

    # for each unique pattern
    for (i in 1:nrow(my.unique.patterns)) {
        # determine which samples conform to that pattern
        in.pattern <- apply(my.model, 1, function(row) {all(row == my.unique.patterns[i,])})
    # get counts just in those samples
    in.counts <- rowMeans(my.normalized.counts[,in.pattern])
    counts.list[[name]] <- cbind(counts.list[[name]], in.counts)
    colnames(counts.list[[name]])[ncol(counts.list[[name]])] <- format.group.name(my.unique.patterns[i,])
    }
}
```


# Exported results

```{r selections}
sel.list <- list()
for (name in names(res.list)){
  res <- res.list[[name]][['res']]

  # NOTE: significance level
  alpha <- 0.1

  # NOTE: any other selections?
  #    Here we just get the up- and downregulated genes, but any arbitrary
  #    subsets of the results can be added.
  #
  #    For each selection:
  #      - TSV of the subset of genes will be written to file and a link
  #        created for it in the Markdown
  #      - GO analysis will be performed on each group separately below.
  sel.list[[name]] <- list(
    up=res[get.sig(res, alpha=alpha, direction='up'),],
    dn=res[get.sig(res, alpha=alpha, direction='dn'),]
    )
}
```

```{r, results='asis'}
# Write out files for full and each selection, and create a link to them in the
# HTML generated by this RMarkdown.
for (name in names(res.list)){
  mdcat('## ', res.list[[name]][['label']])
  fn <- paste0(name, '.tsv')
  write.table(res.list[[name]][['res']], file=fn, row.names=FALSE, sep='\t')
  write.table(counts.list[[name]], file=paste(fn, ".counts", sep=""), row.names=FALSE, sep="\t")
  mdcat('- [', fn, '](', fn, '), results for ', res.list[[name]][['label']])

  # Selections defined above written out to file, and a Markdown link created.
  for (sel in names(sel.list[[name]])){
    fn <- paste0(name, '.', sel, '.tsv')
    write.table(sel.list[[name]][[sel]], file=fn, row.names=FALSE, sep='\t')
    mdcat('- [', fn, '](', fn, '), just the "', sel, '" genes for ', res.list[[name]][['label']])
  }
}
```

# Gene ontology and KEGG pathway enrichment

Here we perform gene ontology enrichment and KEGG pathway enrichment using the
[clusterProfiler](https://bioconductor.org/packages/release/bioc/vignettes/clusterProfiler/inst/doc/clusterProfiler.html)
package with some custom plotting functions.


```{r GO, cache=TRUE}
# NOTE: computationally intensive.
#    clusterProfiler can take a long time to run. You may want to disable this
#    chunk to speed things up.

# Here we summarize the results into dataframes and attach additional
# information to them such that they can be concatenated together into a large
# tidy dataframe.
universe <- names(dds)
enrich.list <- list()
for (name in names(sel.list)){
  for (sel in names(sel.list[[name]])){
    sel.res <- sel.list[[name]][[sel]]

    # GO enrichment
    go.label <- paste(name, sel, 'go', sep='.')
    message(paste(go.label, '...'))
    sg <- summarize.go(
      clusterprofiler.enrichgo(sel.res$gene, universe, orgdb),
      list(label=go.label, sel=sel, experiment=name))
    if (!is.null(sg)){
      enrich.list[[go.label]] <- sg
    }

    # KEGG enrichment
    kegg.label <- paste(name, sel, 'kegg', sep='.')
    message(paste(kegg.label, '...'))
    sk <- summarize.kegg(
      clusterprofiler.enrichkegg(sel.res$uniprot, kegg.org),
      list(label=kegg.label, sel=sel, experiment=name))
    if (!is.null(sk)){
      enrich.list[[kegg.label]] <- sk
    }
  }
}
```

These plots show:

- enriched category (y-axis)
- magnitude of enrichment (x-axis; plotted as -10 log10 (FDR) or "phred" scale)
- fraction of regulated genes falling within a particular category (size)
- experiment (color)
- ontology (sub-panels; BP=biological process, MF=molecular function,
  CC=cellular component, kegg=KEGG pathway)
- direction of regulation (up- or downregulated; separate figures; labeled at the top)

The plots show the top 50 terms, and are sorted by the max enrichment across
experiments.

```{r fullenrich, cache=TRUE}
full.enrich.table <- do.call(rbind, enrich.list)
write.table(full.enrich.table, file='functional_enrichment.tsv', row.names=FALSE, sep='\t')
```

The full analysis table can be viewed here:

- [functional_enrichment.tsv](functional_enrichment.tsv)

```{r, go, fig.height=15, fig.width=15, dev=c('pdf', 'png')}
# While clusterProfiler has canned figures, it's difficult to customize them.
# Instead, here we create a tidy dataframe of all experiments, directions, and
# enrichment analyses so that we can plot them with ggplot2 however the
# experiment dictates


lim <- 50
nchunks <- 1

# NOTE: we assume that all experiments have the same selections.
#
#    This is the default case from the above "selections" chunk.
for (sel in names(sel.list[[1]])){
  mdcat('## ', sel)
  m <- do.call(rbind, enrich.list)

  # Some GO descriptions are really long. To keep the plot dimensions
  # reasonable, we will be truncating them all to the 75th percentile.
  length.quantile <- quantile(nchar(as.vector(m$Description, mode="character")), 0.75)

  # convert to phred score, and flip the "downregulated"
  m$phred <- -10 * log10(m$p.adjust)
  idx <- m$sel == sel

  m <- m[idx,]

  if (nrow(m) == 0){next}

  #replace ontology descriptions with truncations to make plot prettier
  temp.desc <- as.vector(m$Description, mode="character")
  needs.replacement <- which(nchar(temp.desc) > length.quantile)
  temp.desc <- strtrim(temp.desc, length.quantile)
  temp.desc[needs.replacement] <- paste(temp.desc[needs.replacement], "...", sep="")
  m$Description <- factor(temp.desc)

  # Grab the top (ordered by phred)
  max.per.term <- aggregate(phred~Description, m, FUN=max)
  o <- rev(order(max.per.term$phred))
  m$Description <- factor(m$Description, levels=rev(max.per.term$Description[o]))
  top.terms <- (max.per.term$Description[o][seq(lim)])
  m.sub <- m[m$Description %in% top.terms,]
  m.sub$Description <- droplevels(m.sub$Description)
  levels(m.sub$Description) <- max.per.term$Description[o]
  #m.sub <- m.sub[order(m.sub$Description),]

  chunksize <- ceiling(lim / nchunks)
  lookup <- rep(1:nchunks, each=chunksize)
  m.sub$chunk <- 0
  for (i in seq(length(lookup))){
    term <- as.character(top.terms[i])
    lab <- lookup[i]
    m.sub$chunk[m.sub$Description == term] = lab
  }


print(ggplot(m.sub) +
    geom_point(alpha=0.6) +
    aes(y=Description, x=phred, size=frac, color=experiment) +
    theme(text=element_text(size=12)) +
    facet_grid(ontology~sel, scales='free_y', space='free_y')
  )
}
```

# Session info
For reproducibility purposes, here is the output of `sessionInfo()` showing the
versions of all packages used here.

```{r, collapse=FALSE}
sessionInfo()
```

# Help

```{r helpdocs, child="help_docs.Rmd", run_pandoc=FALSE}
# NOTE: optional help section
#   Delete this chunk, or set to eval=FALSE, if you don't want to include the
#   help text from "help_docs.Rmd"
```

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell Type Level Permutation Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After talking with Cameron he suggested a different permutation algorithm as follows.\n",
    "\n",
    "1. For each cell calculate Mann-Whitney U on normalized counts for X vs A. Use the p-value to determine if a cell is depleted of X.\n",
    "2. For each cell type cluster, calculate the proportion of cells with depleted X. \n",
    "3. Permute cluster labels and build null distributions of proportion of depleted cells for each cluster size.\n",
    "4. Use the corresponding null distribution to calculate emperical p-values for each cluster.\n",
    "\n",
    "The one thing that needs worked out is how to \"normalize\" cell counts. In principle, we have the following things we can normalize by:\n",
    "* (X) number of reads per cell\n",
    "    * I am doing on calculations within a cell so I don't think we need to account for this\n",
    "* (X) gene length\n",
    "    * 10X is 3' biased, so I don't think gene length really needs to be accounted for\n",
    "* (X) chromosome length\n",
    "    * These counts are at the gene level, so chromosome length does not come into play\n",
    "* (Maybe) number genes per chromosome\n",
    "* (Maybe) number of expressed genes per chromosome\n",
    "* (Maybe) proportion of genes expressed per chromosome (number of expressed genes per chromosome / number genes per chromosome)\n",
    "    * This combines the other two (Maybe) into a single value.\n",
    "\n",
    "I will try without normalization first and see how different clusters behave. I will then explore using the (Maybe) values to affect some kind of normalization. \n",
    "\n",
    "I also need to decide how to incorporate replicate information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Project level imports\n",
    "from larval_gonad.notebook import Nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup notebook\n",
    "nbconfig = Nb.setup_notebook(seurat_dir='../output/scrnaseq-wf/scrnaseq_combine_force')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of FBgns by chromosome\n",
    "\n",
    "1. Pull out the major autosomes and X.\n",
    "2. Relabel autosomes as A to simplify things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping of FBgn to X or A linked genes\n",
    "autosomes = ['chr2L', 'chr2R', 'chr3L', 'chr3R']\n",
    "\n",
    "fbgn2chrom = nbconfig.fbgn2chrom[nbconfig.fbgn2chrom.chrom.isin(autosomes + ['chrX'])].copy()\n",
    "fbgn2chrom = fbgn2chrom.chrom.map(dict(chr2L='A', chr2R='A', chr3L='A', chr3R='A', chrX='X'))\n",
    "fbgn2chrom.value_counts().map(lambda x: f'{x:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in raw coverage counts for replicate 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read rep 2 raw data.\n",
    "raw = pd.read_csv('../output/scrnaseq-wf/scrnaseq_rep2_force/raw.tsv', sep='\\t', index_col=0)\n",
    "raw.index.name = 'FBgn'\n",
    "raw.columns.name = 'cell_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# melt and munge\n",
    "raw_melted = raw.reset_index().melt(id_vars='FBgn', value_name='UMI').set_index('FBgn')\n",
    "raw_melted_expressed = raw_melted[raw_melted.UMI > 0]\n",
    "raw_melted_expressed_w_chrom = raw_melted_expressed.join(fbgn2chrom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_melted_expressed_w_chrom.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate X chromosome depletion\n",
    "\n",
    "For each cell use the Mann-Whitney U test to determine if the median X-linked gene expression is less than the median Autosome linked gene expression. Create a flag `flag_depleted` indicating that X-linked genes were depleted (i.e., Mann-Whitney was significant).\n",
    "\n",
    "*Note: I required that there are at least 100 genes for X and A, but all cells met this criteria.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the proportion of cells with depelete X chromosome expression\n",
    "results = []\n",
    "for cell_id, dd in raw_melted_expressed_w_chrom.groupby('cell_id'):\n",
    "    if dd.chrom.unique().shape[0] == 1:\n",
    "        continue\n",
    "        \n",
    "    x_genes = dd.query('chrom == \"X\"').UMI.values\n",
    "    a_genes = dd.query('chrom == \"A\"').UMI.values\n",
    "\n",
    "    if x_genes.shape[0] < 100 and a_genes.shape[0] < 100:\n",
    "        results.append((cell_id, np.nan))\n",
    "        continue\n",
    "\n",
    "    stat, p_value = mannwhitneyu(x_genes, a_genes, alternative='less')\n",
    "    if p_value < 0.05:\n",
    "        results.append((cell_id, True))\n",
    "    else:\n",
    "        results.append((cell_id, False))\n",
    "\n",
    "flag_depleted = pd.DataFrame(results, columns=['cell_id', 'flag_depleted']).set_index('cell_id').flag_depleted\n",
    "flag_depleted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the proportion of cells with X chromosome depletion for each cell type cluster\n",
    "\n",
    "Using `flag_depleted`, I merge on cell type information and calculate the proportion of cells that showed depletion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on cell type info\n",
    "clusters = nbconfig.seurat.get_clusters('res.0.6').map(nbconfig.short_cluster_annot)\n",
    "clusters = clusters[clusters != 'UNK'].copy()\n",
    "clusters = clusters.astype('category').cat.as_ordered().cat.reorder_categories(nbconfig.short_cluster_order)\n",
    "\n",
    "flag_depleted_w_cluster = pd.concat([flag_depleted, clusters], axis=1, join='inner')\n",
    "obs_prop = flag_depleted_w_cluster.groupby('cluster').flag_depleted.sum() / flag_depleted_w_cluster.groupby('cluster').flag_depleted.size()\n",
    "display(HTML('<h4>Proportion of Cells Depleted by Cluster</h4>'))\n",
    "obs_prop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permute celltype labels and create a null distribution of proportion of cell depleted\n",
    "\n",
    "Now I scramble the celltype labels and recalcualte the proportion of cells depleted for each cell type. This creates a null distribution for each celltype which controls for cluster size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(10_000):\n",
    "    _df = flag_depleted_w_cluster.copy()\n",
    "    _df['cluster'] = _df['cluster'].sample(frac=1, replace=False).values\n",
    "    props = _df.groupby('cluster').flag_depleted.sum() / _df.groupby('cluster').flag_depleted.size()\n",
    "    results.append(props)\n",
    "perm = pd.concat(results, axis=1).T.reset_index(drop=True)\n",
    "perm.plot(kind='kde', title='Null Distributions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare observed proportions to null distribution\n",
    "\n",
    "For each celltype compare the observed proportion of depleted cells with celltype null distribution. Calculate the empirical p-value as the proportion of permuted samples with a more extreme value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for cluster in nbconfig.short_cluster_order:\n",
    "    p_value = (perm[cluster] >= obs_prop[cluster]).sum() / perm.shape[0]\n",
    "    results.append((cluster, p_value))\n",
    "pd.DataFrame(results, columns=['cluster', 'p_value']).set_index('cluster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation of Germline Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_depleted_w_cluster_germline_only = flag_depleted_w_cluster[flag_depleted_w_cluster.cluster.isin(['SP', 'ES', 'MS', 'LS'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permute celltype labels and create a null distribution of proportion of cell depleted\n",
    "\n",
    "Now I scramble the celltype labels and recalcualte the proportion of cells depleted for each cell type. This creates a null distribution for each celltype which controls for cluster size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(10_000):\n",
    "    _df = flag_depleted_w_cluster_germline_only.copy()\n",
    "    _df['cluster'] = _df['cluster'].sample(frac=1, replace=False).values\n",
    "    props = _df.groupby('cluster').flag_depleted.sum() / _df.groupby('cluster').flag_depleted.size()\n",
    "    results.append(props.dropna())\n",
    "perm = pd.concat(results, axis=1).T.reset_index(drop=True)\n",
    "perm.plot(kind='kde', title='Null Distributions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare observed proportions to null distribution\n",
    "\n",
    "For each celltype compare the observed proportion of depleted cells with celltype null distribution. Calculate the empirical p-value as the proportion of permuted samples with a more extreme value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for cluster in nbconfig.short_cluster_order[:4]:\n",
    "    p_value = (perm[cluster] >= obs_prop[cluster]).sum() / perm.shape[0]\n",
    "    results.append((cluster, p_value))\n",
    "pd.DataFrame(results, columns=['cluster', 'p_value']).set_index('cluster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_depleted.to_frame().to_csv('../output/notebook/2019-01-17_prototype_cell_type_permutation_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:larval_gonad]",
   "language": "python",
   "name": "conda-env-larval_gonad-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
